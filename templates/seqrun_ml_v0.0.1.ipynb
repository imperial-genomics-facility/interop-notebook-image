{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from interop_data_plot import read_interop_data\n",
    "from interop_data_plot import read_runinfo_xml\n",
    "from interop_data_plot import calculate_phasing_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqrun_id = '{{ SEQRUN_IGF_ID }}'\n",
    "seqrun_training_data_csv = '{{ SEQRUN_TRAINING_DATA }}'\n",
    "new_seqrun_interop_dump = '{{ NEW_SEQRUN_INTEROP_DUMP }}'\n",
    "new_seqrun_runinfo_xml = '{{ NEW_SEQRUN_RUNINFO_XML }}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(seqrun_training_data_csv)\n",
    "merged_df['q30_pct_mean'] = merged_df['q30_pct_mean'].astype(float)\n",
    "merged_df['total_median'] = merged_df['total_median'].astype(int)\n",
    "merged_df['median_qscore'] = merged_df['median_qscore'].astype(int)\n",
    "merged_df['cluster_count_pct'] = merged_df['cluster_count_pct'].astype(float)\n",
    "merged_df['densityPf_pct'] = merged_df['densityPf_pct'].astype(float)\n",
    "merged_df['MaxIntensity_A'] = merged_df['MaxIntensity_A'].astype(float)\n",
    "merged_df['MaxIntensity_G'] = merged_df['MaxIntensity_G'].astype(float)\n",
    "merged_df['MaxIntensity_T'] = merged_df['MaxIntensity_T'].astype(float)\n",
    "merged_df['MaxIntensity_C'] = merged_df['MaxIntensity_C'].astype(float)\n",
    "merged_df['Focus_A'] = merged_df['Focus_A'].astype(float)\n",
    "merged_df['Focus_G'] = merged_df['Focus_G'].astype(float)\n",
    "merged_df['Focus_T'] = merged_df['Focus_T'].astype(float)\n",
    "merged_df['Focus_C'] = merged_df['Focus_C'].astype(float)\n",
    "merged_df['error_rate'] = merged_df['error_rate'].astype(float)\n",
    "merged_df['phasing_slope'] = merged_df['phasing_slope'].astype(float)\n",
    "merged_df['phasing_offset'] = merged_df['phasing_offset'].astype(float)\n",
    "merged_df['prephasing_slope'] = merged_df['prephasing_slope'].astype(float)\n",
    "merged_df['prephasing_offset'] = merged_df['prephasing_offset'].astype(float)\n",
    "merged_df['obs_failed'] = merged_df['obs_failed'].astype(int)\n",
    "targets = merged_df['obs_failed'].values\n",
    "merged_df.drop(['lane_id','is_sc', 'is_failed','seqrun_id','obs_failed'],axis=1,inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df, targets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([(\n",
    "    'scaled',StandardScaler(),\n",
    "    ['q30_pct_mean', 'total_median', 'median_qscore', 'cluster_count_pct',\n",
    "     'densityPf_pct', 'MaxIntensity_A', 'MaxIntensity_G', 'MaxIntensity_T',\n",
    "     'MaxIntensity_C', 'Focus_A', 'Focus_G', 'Focus_T', 'Focus_C',\n",
    "     'error_rate', 'phasing_slope', 'phasing_offset', 'prephasing_slope',\n",
    "     'prephasing_offset'])])\n",
    "ct.fit(X_train)\n",
    "X_train_scaled = ct.transform(X_train)\n",
    "X_test_scaled = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42,max_depth=7)\n",
    "model.fit(X_train_scaled ,y_train)\n",
    "print('Training score: {0:.3f}'.format(model.score(X_train_scaled,y_train)))\n",
    "print('Test score: {0:.3f}'.format(model.score(X_test_scaled,y_test)))\n",
    "precision_rf,recall_rf,threshold_rf = precision_recall_curve(y_test,model.predict_proba(X_test_scaled)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(precision_rf,recall_rf,label=\"precision recall curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precision score: {0:.3f}'.format(average_precision_score(y_test,model.predict_proba(X_test_scaled)[:,1])))\n",
    "print('F1 score: {0:.3f}'.format(f1_score(y_test,model.predict(X_test_scaled))))\n",
    "fpr,tpr,thresholds = \\\n",
    "  roc_curve(y_test,model.predict_proba(X_test_scaled)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr,label='ROC')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Area under curve: {0:.3f}'.format(roc_auc_score(y_test,model.predict_proba(X_test_scaled)[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test,model.predict(X_test_scaled))\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_matircs(seqrun_id,interop_dump,runinfo_xml):\n",
    "  try:\n",
    "    (tile,q2030,extraction,error,empiricalPhasing,correctedInt,qByLane) = \\\n",
    "      read_interop_data(filepath=interop_dump)\n",
    "    runinfoDf = read_runinfo_xml(runinfo_xml)\n",
    "    cycles_list = \\\n",
    "      runinfoDf[runinfoDf['index_read']=='N'][\n",
    "        ['read_id','cycles','start_cycle']].\\\n",
    "        to_dict(orient='records')\n",
    "    non_index_cycles = list()\n",
    "    non_index_ids = list()\n",
    "    for entry in cycles_list:\n",
    "      read_id = entry.get('read_id')\n",
    "      cycles = entry.get('cycles')\n",
    "      start_cycle = entry.get('start_cycle')\n",
    "      finish_cycle = start_cycle+cycles\n",
    "      non_index_cycles.extend([\n",
    "          i for i in range(start_cycle+1,finish_cycle)])\n",
    "      non_index_ids.append(int(read_id))\n",
    "    q2030['Lane'] = q2030['Lane'].astype(int)\n",
    "    q2030['Cycle'] = q2030['Cycle'].astype(int)\n",
    "    q2030['Tile'] = q2030['Tile'].astype(int)\n",
    "    q2030['Q30'] = q2030['Q30'].astype(int)\n",
    "    q2030['Total'] = q2030['Total'].astype(int)\n",
    "    q2030['MedianQScore'] = q2030['MedianQScore'].astype(int)\n",
    "    q2030df = list()\n",
    "    for lane_id,l_data in q2030.groupby('Lane'):\n",
    "      q30_median = \\\n",
    "        l_data[l_data['Cycle'].isin(non_index_cycles)].\\\n",
    "        groupby('Tile')['Q30'].\\\n",
    "        agg('median').mean()\n",
    "      total_median = \\\n",
    "        l_data[l_data['Cycle'].isin(non_index_cycles)].\\\n",
    "        groupby('Tile')['Total'].\\\n",
    "        agg('median').mean()\n",
    "      q30_pct = q30_median / total_median\n",
    "      median_qscore_mean = \\\n",
    "        l_data[l_data['Cycle'].isin(non_index_cycles)].\\\n",
    "        groupby('Tile')['MedianQScore'].\\\n",
    "        agg('median').mean()\n",
    "      row = {\n",
    "        'lane_id':lane_id,\n",
    "        'q30_pct_mean':q30_pct,\n",
    "        'total_median':total_median,\n",
    "        'median_qscore':median_qscore_mean}\n",
    "      q2030df.append(row)\n",
    "    q2030df = pd.DataFrame(q2030df).fillna(0)\n",
    "    tile_filt = tile[tile['Lane'].isin(['1','2','3','4','5','6','7','8'])].copy()\n",
    "    tile_filt['Lane'] = tile_filt['Lane'].astype(int)\n",
    "    tile_filt['Read'] = tile_filt['Read'].astype(int)\n",
    "    tile_filt['ClusterCount'] = tile_filt['ClusterCount'].astype(float)\n",
    "    tile_filt['ClusterCountPF'] = tile_filt['ClusterCountPF'].astype(float)\n",
    "    tile_filt['Density'] = tile_filt['Density'].astype(float)\n",
    "    tile_filt['DensityPF'] = tile_filt['DensityPF'].astype(float)\n",
    "    tiledf = list()\n",
    "    for lane_id,l_data in tile_filt.groupby('Lane'):\n",
    "      l_data_sum = \\\n",
    "        l_data[l_data['Read'].isin(non_index_ids)].groupby('Tile')[\n",
    "          ['ClusterCount','ClusterCountPF','Density','DensityPF']].\\\n",
    "          agg('sum').mean()\n",
    "      cluster_countPf_pct = \\\n",
    "        l_data_sum['ClusterCountPF'] / l_data_sum['ClusterCount']\n",
    "      densityPf_pct = \\\n",
    "        l_data_sum['DensityPF'] / l_data_sum['Density']\n",
    "      row = {\n",
    "        'lane_id':lane_id,\n",
    "        'cluster_count_pct':cluster_countPf_pct,\n",
    "        'densityPf_pct':densityPf_pct}\n",
    "      tiledf.append(row)\n",
    "    tiledf = pd.DataFrame(tiledf).fillna(0)\n",
    "    extraction['Lane'] = extraction['Lane'].astype(int)\n",
    "    extraction['Tile'] = extraction['Tile'].astype(int)\n",
    "    extraction['Cycle'] = extraction['Cycle'].astype(int)\n",
    "    extraction['MaxIntensity_A'] = extraction['MaxIntensity_A'].astype(int)\n",
    "    extraction['MaxIntensity_T'] = extraction['MaxIntensity_T'].astype(int)\n",
    "    extraction['MaxIntensity_G'] = extraction['MaxIntensity_G'].astype(int)\n",
    "    extraction['MaxIntensity_C'] = extraction['MaxIntensity_C'].astype(int)\n",
    "    extraction['Focus_A'] = extraction['Focus_A'].astype(float)\n",
    "    extraction['Focus_T'] = extraction['Focus_T'].astype(float)\n",
    "    extraction['Focus_G'] = extraction['Focus_G'].astype(float)\n",
    "    extraction['Focus_C'] = extraction['Focus_C'].astype(float)\n",
    "    extractiondf = list()\n",
    "    extraction_columns = [\n",
    "      'MaxIntensity_A','MaxIntensity_G','MaxIntensity_T','MaxIntensity_C',\n",
    "      'Focus_A','Focus_G','Focus_T','Focus_C']\n",
    "    for lane_id,l_data in extraction.groupby('Lane'):\n",
    "      e_data_mean = \\\n",
    "        l_data[l_data['Cycle'].isin(non_index_cycles)].\\\n",
    "        groupby('Tile')[extraction_columns].\\\n",
    "        agg('median').mean()\n",
    "      row = {'lane_id':lane_id}\n",
    "      for c in extraction_columns:\n",
    "        row.update({c:e_data_mean.get(c)})\n",
    "      extractiondf.append(row)\n",
    "    extractiondf = pd.DataFrame(extractiondf).fillna(0)\n",
    "    error['Lane'] = error['Lane'].astype(int)\n",
    "    error['Tile'] = error['Tile'].astype(int)\n",
    "    error['Cycle'] = error['Cycle'].astype(int)\n",
    "    error['ErrorRate'] = error['ErrorRate'].astype(float)\n",
    "    errordf = list()\n",
    "    for lane_id,l_data in error.groupby('Lane'):\n",
    "      l_data_mean = \\\n",
    "        l_data[l_data['Cycle'].isin(non_index_cycles)].\\\n",
    "        groupby('Tile')[['ErrorRate']].\\\n",
    "        agg('median').mean()\n",
    "      error_rate = l_data_mean['ErrorRate']\n",
    "      errordf.append({'lane_id':lane_id,'error_rate':error_rate})\n",
    "    if len(errordf)>0:\n",
    "      errordf = pd.DataFrame(errordf).fillna(0)\n",
    "    else:\n",
    "      errordf = pd.DataFrame(columns=['lane_id','error_rate'])\n",
    "    phasing_data = \\\n",
    "      calculate_phasing_stats(empiricalPhasing,runinfoDf)\n",
    "    phasing_columns = [\n",
    "      'phasing_slope','phasing_offset',\n",
    "      'prephasing_slope','prephasing_offset']\n",
    "    for c in phasing_columns:\n",
    "      phasing_data[c] = phasing_data[c].astype(float)\n",
    "    phasing_df = list()\n",
    "    for lane_id,l_data in phasing_data.groupby('lane_id'):\n",
    "      p_data = \\\n",
    "        l_data[l_data['read_id'].isin([1,4])][phasing_columns].mean()\n",
    "      row = {'lane_id':lane_id}\n",
    "      for c in phasing_columns:\n",
    "        row.update({c:p_data.get(c)})\n",
    "      phasing_df.append(row)\n",
    "    phasing_df = pd.DataFrame(phasing_df).fillna(0)\n",
    "    merged_df = \\\n",
    "      q2030df.merge(tiledf,on='lane_id',how='left').\\\n",
    "      merge(extractiondf,on='lane_id',how='left').\\\n",
    "      merge(errordf,on='lane_id',how='left').\\\n",
    "      merge(phasing_df,on='lane_id',how='left').\\\n",
    "      fillna(0)\n",
    "    merged_df['seqrun_id'] = seqrun_id\n",
    "    return merged_df\n",
    "  except:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = \\\n",
    "  get_run_matircs(\n",
    "    seqrun_id=seqrun_id,\n",
    "    interop_dump=new_seqrun_interop_dump,\n",
    "    runinfo_xml=new_seqrun_runinfo_xml)\n",
    "seqrun_ids = df[['seqrun_id','lane_id']].copy()\n",
    "df.drop(['lane_id','seqrun_id'],axis=1,inplace=True)\n",
    "df_scaled = ct.transform(df)\n",
    "seqrun_ids['is_low'] = model.predict(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_seqrun_prediction(s):\n",
    "    if s.is_low == 1:\n",
    "        bgcolors = ['','','background:crimson']\n",
    "    else:\n",
    "        bgcolors = ['','','background:lightgreen']\n",
    "    return bgcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqrun_ids.style.apply(lambda s: color_seqrun_prediction(s),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
